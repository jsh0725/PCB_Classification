# 2025-1-DL_PCB

<정시훈(조원)>

### 📌 2025.05.23
- Binary Classification 모델을 `jsh0725` 브랜치에 `predict.py` 파일로 업로드했습니다.
- 주석을 통해 코드 설명을 추가했으며, 지속적으로 수정 및 보완하고 있습니다.
- 모델은 총 3종 구성되어 있으며, 모델 2, 3번은 대용량 처리를 고려한 구조로 설계되었고, 이후 다른 모델로 대체할 예정입니다.
- 학습/검증 데이터 및 모델 성능 시각화 코드도 포함되어 있습니다.

### 📌 2025.05.25
- model_4, model_5를 포함한 전체 코드 업데이트 완료. (올려주셨던 파일이랑 합쳐놓은 상태입니다.)
- model_2는 `sigmoid` + `binary_crossentropy` 구조로 변경하였습니다.
- `visualize_all_models.py` 실행 시 학습 및 검증 정확도를 시각화해 과적합 여부를 파악할 수 있습니다.
- 이미지가 흑백 이미지로 구성되어 있어 RGB 3채널로 구성에서 흑백의 1채널로 바꾸어 학습하였으니 참고 부탁드립니다.
#### ✅ 현재 모델별 테스트 정확도:
- **Model 1, 2**: 약 90% 이상 → 가장 우수한 성능
- **Model 5**: 약 70%
- **Model 3, 4**: 약 50%로, 학습이 거의 되지 않은 상태로 추정됨

---

**💡 건의사항**  
여러 모델을 구성해보며 실험한 결과, 가능한 한 **정확도 100%에 근접**하는 방향이 바람직하다고 판단됩니다.  
혹시 이와 관련하여 **더 나은 구조나 개선 아이디어가 있다면 공유 부탁드립니다!**

(※ 작성 시간 기준: 23시. 코멘트를 간략히 README에 남깁니다.)

### 2025.05.28
<정유진(조원)>
- model_4의 dropout을 0.6으로 했을 때 훈련 정확도가 검증 정확도보다 5%낮아서 다시 수정중입니다
- 21:15 훈련 정확도는 98% 검증정확도는 93%가 나왔습니다
- 구조 개선 부분에서 콜백함수를 적용해서 에폭을 100으로 설정한 후 가장 나은 정확도와 손실률이 나온다면 모델 학습이 끝나도록 하는 코드를 적용하는것은 어떨까요?
- 제 branch에 model_4 수정한 부분과 같이 적어놓겠습니다.

### 2025.05.30
<정시훈(조원)>
- model_3 data Augmentation 모델로 변경해놨습니다.
- 학습은 잘 되는거 같은데 분명 모든 모델에서 과적합이 일어나고 있습니다. 그래서 콜백 함수를 도입하니 너무 이른 부분에서 학습이 중단되고 값을 조정해봐도 깔끔한 해결이 되지 않네요;; 같이 고민해봐야 할 듯 싶습니다(이번주 주말 안으로 끝내야 싶습니다 얼마 안남았네요)
- 일단 한 것 까지는 main 브랜치에 업데이트 해 놨습니다! 연락이 길어질 거 같아서 말씀드리고 싶은 부분은 여기다 적어놓겟습니다

### 2025.05.31
<정유진(조원)>
- 데이터 증강을 모든 모델에 적용해서 하면 어떨까요?
- 지금 현재(16시24분) 4번 모델이 학습이 전혀 안되고 있어 계속 확인중이고 5번모델도 수정중입니다. 카톡으로 알려주시면 감사하겠습니다.

### 2025.05.31
<정시훈(조원)>
- model 2, 3번의 블록 수를 3개에서 4개로 늘렸습니다(16 -> 32 -> 64 -> 128 구조로 증가)
- 콜백함수가 멈추는 부분을 기준으로 에폭을 5씩 감소시켰습니다(30 -> 25 -> 20)
- 과적합 부분 및 기타 문제가 아예 없어졌다기 보다는 전보다는 나아진 것 같습니다



### 2025.06.13
<정시훈(조원)>
- 2단계 과제인 Multi - label classification에 대한 아이디어 제안 밑 기초 코드 공유드립니다.

- 관련 내용을 찾아 본 결과, 정상 데이터는 더 이상 필요 없으니 제외하고, 불량 이미지(_test.jpg 파일들)만 사용하면 될 것 같습니다.

- 불량 이미지는 현재 제 브랜치를 들어가보시면 labeling이라는 새로운 폴더를 만들어 그 안에 모두 저장해놨습니다(기존 train 안에 파일은 정상적으로 있으니 필요 시 이용하시면 됩니다.)

- 그리고 이런 불량 이미지들이 어떤 부분이 불량인지(과제에서는 6가지 분류) 알아내려면 Mask 작업을 해서 둘을 1:1 매칭 시킨 후 이를 학습 시켜야 한다고 하더라고요.
  그래서 이 과정이 맞다면 conda의 오픈 소스 툴 킷 중 하나인 "labelme"를 사용해야 합니다.(설치과정 및 사용법을 참고한 블로그 링크 올려드리겠습니다)

- 1500쌍의 데이터 중에서 불량 데이터만을 사용한다면 총 1500개의 라벨링 과정을 해야합니다(지금은 train 폴더 이름-오름차순 정렬 기준으로 00041000 ~ 00041060까지 총 61개의 라벨링을 먼저 해놨습니다. 그리고 labelme를 통해서 라벨링 파일을 만들게 되면 .json 확장자로 저장이 되는데, 기존 불량 이미지와 저장 형식을 맞춰야 하므로 PNG 또는 jpg로 조정해서 처리해야 합니다. 저는 파이썬 코드를 통해 PNG 파일로 변환한 뒤 labling 폴더 내 Mask 폴더에 저장해놨습니다. 주의하셔야 됩니다.)

- 코드는 gpt랑 구글링 통해서 기초까지는 구현해놨으나 학습 데이터의 수가 너무 작아 지금은 정상적으로 되는지에 대한 판단 자체가 어렵습니다. 빠른 시간 내에 라벨링 작업을 착수해야 할 듯 싶습니다.

- 제가 다른 길을 걷는거일수도 있어서 내용 검토해보시고 지적해주시면 감사하겠습니다. 만약 제 방식이 맞다면 1500개 전체는 아니더라도 최대한 많은 수의 데이터 라벨링이 필요해서 홀 / 수 부분을 각자 나누고 매일매일 어디까지 라벨링이 되었는지 공유해야 할 듯 싶습니다)

-궁금한 사항 있으시면 연락 주세요!

labelme 관련 블로그 주소: https://m.blog.naver.com/yh_park02/222315567498